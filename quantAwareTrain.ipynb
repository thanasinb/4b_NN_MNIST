{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thanasinb/4b_NN_MNIST/blob/main/quantAwareTrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QXsrr6Mp5e_"
   },
   "source": [
    "# MNIST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBGOnz5NpiTw"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, mnist=True):\n",
    "      \n",
    "        super(Net, self).__init__()\n",
    "        if mnist:\n",
    "          num_channels = 1\n",
    "        else:\n",
    "          num_channels = 3\n",
    "          \n",
    "        self.conv1 = nn.Conv2d(num_channels, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        if mnist:\n",
    "          self.fc1 = nn.Linear(4*4*50, 500)\n",
    "          self.flatten_shape = 4*4*50\n",
    "        else:\n",
    "          self.fc1 = nn.Linear(1250, 500)\n",
    "          self.flatten_shape = 1250\n",
    "\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        \n",
    "      \n",
    "    def forward(self, x, vis=False, axs=None):\n",
    "        X = 0\n",
    "        y = 0\n",
    "\n",
    "        if vis:\n",
    "          axs[X,y].set_xlabel('Entry into network, input distribution visualised below: ')\n",
    "          visualise(x, axs[X,y])\n",
    "\n",
    "          axs[X,y+1].set_xlabel(\"Visualising weights of conv 1 layer: \")\n",
    "          visualise(self.conv1.weight.data, axs[X,y+1])\n",
    "\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        if vis:\n",
    "          axs[X,y+2].set_xlabel('Output after conv1 visualised below: ')\n",
    "          visualise(x,axs[X,y+2])\n",
    "\n",
    "          axs[X,y+3].set_xlabel(\"Visualising weights of conv 2 layer: \")\n",
    "          visualise(self.conv2.weight.data, axs[X,y+3])\n",
    "\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        if vis:\n",
    "          axs[X,y+4].set_xlabel('Output after conv2 visualised below: ')\n",
    "          visualise(x,axs[X,y+4])\n",
    "\n",
    "          axs[X+1,y].set_xlabel(\"Visualising weights of fc 1 layer: \")\n",
    "          visualise(self.fc1.weight.data, axs[X+1,y])\n",
    "\n",
    "        x = F.max_pool2d(x, 2, 2)  \n",
    "        x = x.view(-1, self.flatten_shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        if vis:\n",
    "          axs[X+1,y+1].set_xlabel('Output after fc1 visualised below: ')\n",
    "          visualise(x,axs[X+1,y+1])\n",
    "\n",
    "          axs[X+1,y+2].set_xlabel(\"Visualising weights of fc 2 layer: \")\n",
    "          visualise(self.fc2.weight.data, axs[X+1,y+2])\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        if vis:\n",
    "          axs[X+1,y+3].set_xlabel('Output after fc2 visualised below: ')\n",
    "          visualise(x,axs[X+1,y+3])\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EWDw3bip8Ie"
   },
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujzd_d1kp_sX",
    "outputId": "512474d0-dca3-4d8d-852d-48fbfc67737f"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "   \n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "def main(mnist=True):\n",
    " \n",
    "    batch_size = 64\n",
    "    test_batch_size = 64\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 500\n",
    "    save_model = False\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "    if mnist:\n",
    "      train_loader = torch.utils.data.DataLoader(\n",
    "          datasets.MNIST('../data', train=True, download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))\n",
    "                        ])),\n",
    "          batch_size=batch_size, shuffle=True, **kwargs)\n",
    "      \n",
    "      test_loader = torch.utils.data.DataLoader(\n",
    "          datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))\n",
    "                        ])),\n",
    "          batch_size=test_batch_size, shuffle=True, **kwargs)\n",
    "    else:\n",
    "      transform = transforms.Compose(\n",
    "          [transforms.ToTensor(),\n",
    "          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "      trainset = datasets.CIFAR10(root='./dataCifar', train=True,\n",
    "                                              download=True, transform=transform)\n",
    "      train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                                shuffle=True, num_workers=2)\n",
    "\n",
    "      testset = datasets.CIFAR10(root='./dataCifar', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "      test_loader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size,\n",
    "                                              shuffle=False, num_workers=2)\n",
    "          \n",
    "  \n",
    "    model = Net(mnist=mnist).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader)\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDkkrT2prCU9"
   },
   "source": [
    "# Quantisation of Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFM8UV9CreIX"
   },
   "source": [
    "## Quantisation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCsoFvwLrgdu"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "QTensor = namedtuple('QTensor', ['tensor', 'scale', 'zero_point'])\n",
    "\n",
    "def calcScaleZeroPoint(min_val, max_val,num_bits=8):\n",
    "  # Calc Scale and zero point of next \n",
    "  qmin = 0.\n",
    "  qmax = 2.**num_bits - 1.\n",
    "\n",
    "  scale = (max_val - min_val) / (qmax - qmin)\n",
    "\n",
    "  initial_zero_point = qmin - min_val / scale\n",
    "  \n",
    "  zero_point = 0\n",
    "  if initial_zero_point < qmin:\n",
    "      zero_point = qmin\n",
    "  elif initial_zero_point > qmax:\n",
    "      zero_point = qmax\n",
    "  else:\n",
    "      zero_point = initial_zero_point\n",
    "\n",
    "  zero_point = int(zero_point)\n",
    "\n",
    "  return scale, zero_point\n",
    "\n",
    "def calcScaleZeroPointSym(min_val, max_val,num_bits=8):\n",
    "  \n",
    "  # Calc Scale \n",
    "  max_val = max(abs(min_val), abs(max_val))\n",
    "  qmin = 0.\n",
    "  qmax = 2.**(num_bits-1) - 1.\n",
    "\n",
    "  scale = max_val / qmax\n",
    "\n",
    "  return scale, 0\n",
    "\n",
    "def quantize_tensor(x, num_bits=8, min_val=None, max_val=None):\n",
    "    \n",
    "    if not min_val and not max_val: \n",
    "      min_val, max_val = x.min(), x.max()\n",
    "\n",
    "    qmin = 0.\n",
    "    qmax = 2.**num_bits - 1.\n",
    "\n",
    "    scale, zero_point = calcScaleZeroPoint(min_val, max_val, num_bits)\n",
    "    q_x = zero_point + x / scale\n",
    "    q_x.clamp_(qmin, qmax).round_()\n",
    "    q_x = q_x.round().byte()\n",
    "    \n",
    "    return QTensor(tensor=q_x, scale=scale, zero_point=zero_point)\n",
    "\n",
    "def dequantize_tensor(q_x):\n",
    "    return q_x.scale * (q_x.tensor.float() - q_x.zero_point)\n",
    "\n",
    "def quantize_tensor_sym(x, num_bits=8, min_val=None, max_val=None):\n",
    "    \n",
    "    if not min_val and not max_val: \n",
    "      min_val, max_val = x.min(), x.max()\n",
    "\n",
    "    max_val = max(abs(min_val), abs(max_val))\n",
    "    qmin = 0.\n",
    "    qmax = 2.**(num_bits-1) - 1.\n",
    "\n",
    "    scale = max_val / qmax   \n",
    "\n",
    "    q_x = x/scale\n",
    "\n",
    "    q_x.clamp_(-qmax, qmax).round_()\n",
    "    q_x = q_x.round()\n",
    "    return QTensor(tensor=q_x, scale=scale, zero_point=0)\n",
    "\n",
    "def dequantize_tensor_sym(q_x):\n",
    "    return q_x.scale * (q_x.tensor.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXkTAJ9ws1Y6"
   },
   "source": [
    "## Rework Forward pass of Linear and Conv Layers to support Quantisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5xNLrchrI6u"
   },
   "outputs": [],
   "source": [
    "def quantizeLayer(x, layer, stat, scale_x, zp_x, vis=False, axs=None, X=None, y=None, sym=False, num_bits=8):\n",
    "  # for both conv and linear layers\n",
    "\n",
    "  # cache old values\n",
    "  W = layer.weight.data\n",
    "  B = layer.bias.data\n",
    "\n",
    "  # WEIGHTS SIMULATED QUANTISED\n",
    "\n",
    "  # quantise weights, activations are already quantised\n",
    "  if sym:\n",
    "    w = quantize_tensor_sym(layer.weight.data,num_bits=num_bits) \n",
    "    b = quantize_tensor_sym(layer.bias.data,num_bits=num_bits)\n",
    "  else:\n",
    "    w = quantize_tensor(layer.weight.data, num_bits=num_bits) \n",
    "    b = quantize_tensor(layer.bias.data, num_bits=num_bits)\n",
    "\n",
    "  layer.weight.data = w.tensor.float()\n",
    "  layer.bias.data = b.tensor.float()\n",
    "\n",
    "  ## END WEIGHTS QUANTISED SIMULATION\n",
    "\n",
    "\n",
    "  if vis:\n",
    "    axs[X,y].set_xlabel(\"Visualising weights of layer: \")\n",
    "    visualise(layer.weight.data, axs[X,y])\n",
    "\n",
    "  # QUANTISED OP, USES SCALE AND ZERO POINT TO DO LAYER FORWARD PASS. (How does backprop change here ?)\n",
    "  # This is Quantisation Arithmetic\n",
    "  scale_w = w.scale\n",
    "  zp_w = w.zero_point\n",
    "  scale_b = b.scale\n",
    "  zp_b = b.zero_point\n",
    "  \n",
    "  if sym:\n",
    "    scale_next, zero_point_next = calcScaleZeroPointSym(min_val=stat['min'], max_val=stat['max'])\n",
    "  else:\n",
    "    scale_next, zero_point_next = calcScaleZeroPoint(min_val=stat['min'], max_val=stat['max'])\n",
    "\n",
    "  # Preparing input by saturating range to num_bits range.\n",
    "  if sym:\n",
    "    X = x.float()\n",
    "    layer.weight.data = ((scale_x * scale_w) / scale_next)*(layer.weight.data)\n",
    "    layer.bias.data = (scale_b/scale_next)*(layer.bias.data)\n",
    "  else:\n",
    "    X = x.float() - zp_x\n",
    "    layer.weight.data = ((scale_x * scale_w) / scale_next)*(layer.weight.data - zp_w)\n",
    "    layer.bias.data = (scale_b/scale_next)*(layer.bias.data + zp_b)\n",
    "\n",
    "  # All int computation\n",
    "  if sym:  \n",
    "    x = (layer(X)) \n",
    "  else:\n",
    "    x = (layer(X)) + zero_point_next \n",
    "  \n",
    "  # cast to int\n",
    "  x.round_()\n",
    "\n",
    "  # Perform relu too\n",
    "  x = F.leaky_relu(x)\n",
    "\n",
    "  # Reset weights for next forward pass\n",
    "  layer.weight.data = W\n",
    "  layer.bias.data = B\n",
    "  \n",
    "  return x, scale_next, zero_point_next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgkWg605tE1y"
   },
   "source": [
    "## Get Stats for Quantising Activations of Network.\n",
    "\n",
    "This is done by running the network with around 1000 examples and getting the average min and max activation values before and after each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GecOkNLhtVh9"
   },
   "outputs": [],
   "source": [
    "# Get Min and max of x tensor, and stores it\n",
    "def updateStats(x, stats, key):\n",
    "  max_val, _ = torch.max(x, dim=1)\n",
    "  min_val, _ = torch.min(x, dim=1)\n",
    "\n",
    "  # add ema calculation\n",
    "\n",
    "  if key not in stats:\n",
    "    stats[key] = {\"max\": max_val.sum(), \"min\": min_val.sum(), \"total\": 1}\n",
    "  else:\n",
    "    stats[key]['max'] += max_val.sum().item()\n",
    "    stats[key]['min'] += min_val.sum().item()\n",
    "    stats[key]['total'] += 1\n",
    "  \n",
    "  weighting = 2.0 / (stats[key]['total']) + 1\n",
    "\n",
    "  if 'ema_min' in stats[key]:\n",
    "    stats[key]['ema_min'] = weighting*(min_val.mean().item()) + (1- weighting) * stats[key]['ema_min']\n",
    "  else:\n",
    "    stats[key]['ema_min'] = weighting*(min_val.mean().item())\n",
    "\n",
    "  if 'ema_max' in stats[key]:\n",
    "    stats[key]['ema_max'] = weighting*(max_val.mean().item()) + (1- weighting) * stats[key]['ema_max']\n",
    "  else: \n",
    "    stats[key]['ema_max'] = weighting*(max_val.mean().item())\n",
    "\n",
    "  stats[key]['min_val'] = stats[key]['min']/ stats[key]['total']\n",
    "  stats[key]['max_val'] = stats[key]['max']/ stats[key]['total']\n",
    "  \n",
    "  return stats\n",
    "\n",
    "# Reworked Forward Pass to access activation Stats through updateStats function\n",
    "def gatherActivationStats(model, x, stats):\n",
    "\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv1')\n",
    "  \n",
    "  x = F.relu(model.conv1(x))\n",
    "\n",
    "  x = F.max_pool2d(x, 2, 2)\n",
    "  \n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv2')\n",
    "  \n",
    "  x = F.relu(model.conv2(x))\n",
    "\n",
    "  x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "  x = x.view(-1, 4*4*50)\n",
    "  \n",
    "  stats = updateStats(x, stats, 'fc1')\n",
    "\n",
    "  x = F.relu(model.fc1(x))\n",
    "  \n",
    "  stats = updateStats(x, stats, 'fc2')\n",
    "\n",
    "  x = model.fc2(x)\n",
    "\n",
    "  return stats\n",
    "\n",
    "# Entry function to get stats of all functions.\n",
    "def gatherStats(model, test_loader):\n",
    "    device = 'cuda'\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    stats = {}\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            stats = gatherActivationStats(model, data, stats)\n",
    "    \n",
    "    final_stats = {}\n",
    "    for key, value in stats.items():\n",
    "      final_stats[key] = { \"max\" : value[\"max\"] / value[\"total\"], \"min\" : value[\"min\"] / value[\"total\"], \"ema_min\": value[\"ema_min\"], \"ema_max\": value[\"ema_max\"] }\n",
    "    return final_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBt0WDzyujnk"
   },
   "source": [
    "## Forward Pass for Quantised Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6duGNF_uoZB"
   },
   "outputs": [],
   "source": [
    "def quantForward(model, x, stats, vis=False, axs=None, sym=False, num_bits=8):\n",
    "  X = 0\n",
    "  y = 0\n",
    "  # Quantise before inputting into incoming layers\n",
    "  if sym:\n",
    "    x = quantize_tensor_sym(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'], num_bits=num_bits)\n",
    "  else:\n",
    "    x = quantize_tensor(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'], num_bits=num_bits)\n",
    "\n",
    "  if vis:\n",
    "    axs[X,y].set_xlabel('Entry into network, input distribution visualised below: ')\n",
    "    visualise(x.tensor, axs[X,y])\n",
    "  \n",
    "  x, scale_next, zero_point_next = quantizeLayer(x.tensor, model.conv1, stats['conv2'], x.scale, x.zero_point, vis, axs, X=X, y=y+1, sym=sym, num_bits=num_bits)\n",
    "\n",
    "  x = F.max_pool2d(x, 2, 2)\n",
    "  \n",
    "  if vis:\n",
    "    axs[X,y+2].set_xlabel('Output after conv1 visualised below: ')\n",
    "    visualise(x,axs[X,y+2])\n",
    "\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.conv2, stats['fc1'], scale_next, zero_point_next, vis, axs, X=X, y=y+3, sym=sym, num_bits=num_bits)\n",
    "\n",
    "  x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "  if vis:\n",
    "    axs[X,y+4].set_xlabel('Output after conv2 visualised below: ')\n",
    "    visualise(x,axs[X,y+4])\n",
    "\n",
    "  x = x.view(-1, 4*4*50)\n",
    "\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.fc1, stats['fc2'], scale_next, zero_point_next, vis, axs, X=X+1, y=0, sym=sym, num_bits=num_bits)\n",
    "\n",
    "  if vis:\n",
    "    axs[X+1,1].set_xlabel('Output after fc1 visualised below: ')\n",
    "    visualise(x,axs[X+1,1])\n",
    "  \n",
    "  # Back to dequant for final layer\n",
    "  if sym:\n",
    "    x = dequantize_tensor_sym(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n",
    "  else:\n",
    "    x = dequantize_tensor(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n",
    "\n",
    "  if vis:\n",
    "    axs[X+1,2].set_xlabel('Output after fc1 but dequantised visualised below: ')\n",
    "    visualise(x,axs[X+1,2])\n",
    "\n",
    "  x = model.fc2(x)\n",
    "\n",
    "  if vis:\n",
    "    axs[X+1,3].set_xlabel('Unquantised Weights of fc2 layer')\n",
    "    visualise(model.fc2.weight.data,axs[X+1,3])\n",
    "\n",
    "    axs[X+1,2].set_xlabel('Output after fc2 but dequantised visualised below: ')\n",
    "    visualise(x,axs[X+1,4])\n",
    "\n",
    "  return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xC96eesMqYo-"
   },
   "source": [
    "# Testing Function for Quantisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6jKRKSBt0he"
   },
   "outputs": [],
   "source": [
    "def testQuant(model, test_loader, quant=False, stats=None, sym=False, num_bits=8):\n",
    "    device = 'cuda'\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if quant:\n",
    "              output = quantForward(model, data, stats, sym=sym, num_bits=num_bits)\n",
    "            else:\n",
    "              output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bs97rNEXt_my"
   },
   "source": [
    "# Get Accuracy of Non Quantised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YCtbfk9qbGI"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "q_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5j42Q8PKt3lj"
   },
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "QeYlzGG0t4Yp",
    "outputId": "d5b2b90a-60f2-4a2a-ae85-91e03b75a909"
   },
   "outputs": [],
   "source": [
    "testQuant(q_model, test_loader, quant=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JaeISHeuHCb"
   },
   "source": [
    "# Gather Stats of Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "xhiL7OwwuLS6",
    "outputId": "51f35d82-e500-4985-92c6-4c001f53dce6"
   },
   "outputs": [],
   "source": [
    "stats = gatherStats(q_model, test_loader)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMeng9S4uSOX"
   },
   "source": [
    "# Test Quantised Inference Of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "INQggUUQuXyq",
    "outputId": "8f0c1919-9e34-4918-bdac-023a6a39fd27"
   },
   "outputs": [],
   "source": [
    "testQuant(q_model, test_loader, quant=True, stats=stats, sym=False, num_bits=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "1_-hb-WqIgXH",
    "outputId": "aa81b890-8df1-470a-9c91-2a78b72b9d4b"
   },
   "outputs": [],
   "source": [
    "testQuant(q_model, test_loader, quant=True, stats=stats, sym=True, num_bits=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "QTUB1sYikm4h",
    "outputId": "3d7a7f13-4446-4221-c56a-5a8d7f6d8abc"
   },
   "outputs": [],
   "source": [
    "testQuant(q_model, test_loader, quant=True, stats=stats, sym=True, num_bits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rApSucQLlb_6"
   },
   "source": [
    "See, when we go down to 4 bits, the accuracy craters !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miUvOJ5YuEHC"
   },
   "source": [
    "# Visualise Weights and Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxxUxYA2BU3x"
   },
   "outputs": [],
   "source": [
    "def visualise(x, axs):\n",
    "  x = x.view(-1).cpu().numpy()\n",
    "  axs.hist(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgBC03xtTCe4"
   },
   "source": [
    "## Visualise Quantised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "q-_lnplBDwFq",
    "outputId": "103715e9-c4ca-44ff-eec9-8ba761f9bee6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# run through one example and plot weights and activations quantised in real time\n",
    "device = 'cuda'\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = quantForward(q_model, data, stats, vis=True, axs=axs, sym=False)\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "BAapb578IoY4",
    "outputId": "fc84a76c-6c1e-4e33-8816-363dd3d4352a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# run through one example and plot weights and activations quantised in real time\n",
    "device = 'cuda'\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = quantForward(q_model, data, stats, vis=True, axs=axs, sym=True)\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mszPTrYOluym"
   },
   "source": [
    "## Non Quantised Network weights and activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iylGn6_aT5r9",
    "outputId": "9136d269-70d0-4322-8927-d07a6b100f28"
   },
   "outputs": [],
   "source": [
    "# run through one example and plot weights and activations quantised in real time\n",
    "device = 'cuda'\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data, vis=True, axs=axs)\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SDvmMnLq85lp",
    "outputId": "5cb6f4b2-7997-4fc4-94bd-52ac1cdba289"
   },
   "outputs": [],
   "source": [
    "quantisedConv1 = quantize_tensor(model.conv1.weight.data)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "axs.hist(quantisedConv1.tensor.cpu().view(-1).numpy())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "quantisedConv1 = model.conv1.weight.data\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "axs.hist(quantisedConv1.cpu().view(-1).numpy())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "quantisedConv1 = quantize_tensor_sym(model.conv1.weight.data)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "axs.hist(quantisedConv1.tensor.cpu().view(-1).numpy())\n",
    "\n",
    "plt.show()\n",
    "\n",
    "unquantisedConv1 = dequantize_tensor_sym(quantisedConv1)\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "axs.hist(unquantisedConv1.cpu().view(-1).numpy())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voLb1LPkvkz_"
   },
   "source": [
    "## TA DA !!\n",
    "\n",
    "We have quantised our net to mostly 8 bit arithmetic with almost zero accuracy loss ! Pretty good day's work, I'll say :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcxOV-GEy6rD"
   },
   "source": [
    "# Quantisation Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDKoL7ncKeb5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class FakeQuantOp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, num_bits=8, min_val=None, max_val=None):\n",
    "        x = quantize_tensor(x,num_bits=num_bits, min_val=min_val, max_val=max_val)\n",
    "        x = dequantize_tensor(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # straight through estimator\n",
    "        return grad_output, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "vSLtlCSOZ7Ve",
    "outputId": "00dfc34b-ff38-4ffe-bbd5-f5ec4945e65a"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3,4]).float()\n",
    "print(FakeQuantOp.apply(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTHK-wAWV57B"
   },
   "source": [
    "## Quantization Aware Training Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lShb-FGKRp1h"
   },
   "outputs": [],
   "source": [
    "def quantAwareTrainingForward(model, x, stats, vis=False, axs=None, sym=False, num_bits=8, act_quant=False):\n",
    "  \n",
    "  conv1weight = model.conv1.weight.data\n",
    "  model.conv1.weight.data = FakeQuantOp.apply(model.conv1.weight.data, num_bits)\n",
    "  x = F.relu(model.conv1(x))\n",
    "\n",
    "  with torch.no_grad():\n",
    "    stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv1')\n",
    "\n",
    "  if act_quant:\n",
    "    x = FakeQuantOp.apply(x, num_bits, stats['conv1']['ema_min'], stats['conv1']['ema_max'])\n",
    "\n",
    "  x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "  conv2weight = model.conv2.weight.data\n",
    "  model.conv2.weight.data = FakeQuantOp.apply(model.conv2.weight.data, num_bits)\n",
    "  x = F.relu(model.conv2(x))\n",
    "\n",
    "  with torch.no_grad():\n",
    "    stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv2')\n",
    "    \n",
    "  if act_quant:\n",
    "    x = FakeQuantOp.apply(x, num_bits, stats['conv2']['ema_min'], stats['conv2']['ema_max'])\n",
    "\n",
    "\n",
    "  x = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "  x = x.view(-1, 4*4*50)\n",
    "\n",
    "  fc1weight = model.fc1.weight.data\n",
    "  model.fc1.weight.data = FakeQuantOp.apply(model.fc1.weight.data, num_bits)\n",
    "  x = F.relu(model.fc1(x))\n",
    "\n",
    "  with torch.no_grad():\n",
    "    stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'fc1')\n",
    "\n",
    "  if act_quant:\n",
    "    x = FakeQuantOp.apply(x, num_bits, stats['fc1']['ema_min'], stats['fc1']['ema_max'])\n",
    "\n",
    "  x = model.fc2(x)\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'fc2')\n",
    "\n",
    "  return F.log_softmax(x, dim=1), conv1weight, conv2weight, fc1weight, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCyUw4izk41q"
   },
   "source": [
    "# Train using Quantization Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "id": "LuKYWJfSR65B",
    "outputId": "171a6c6f-adc5-4e70-d12f-151c1ce80633"
   },
   "outputs": [],
   "source": [
    "def trainQuantAware(args, model, device, train_loader, optimizer, epoch, stats, act_quant=False, num_bits=4):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, conv1weight, conv2weight, fc1weight, stats = quantAwareTrainingForward(model, data, stats, num_bits=num_bits, act_quant=act_quant)\n",
    "\n",
    "        model.conv1.weight.data = conv1weight\n",
    "        model.conv2.weight.data = conv2weight\n",
    "        model.fc1.weight.data = fc1weight\n",
    "\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return stats\n",
    "\n",
    "def testQuantAware(args, model, device, test_loader, stats, act_quant, num_bits=4):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, conv1weight, conv2weight, fc1weight, _ = quantAwareTrainingForward(model, data, stats, num_bits=num_bits, act_quant=act_quant)\n",
    "            \n",
    "            model.conv1.weight.data = conv1weight\n",
    "            model.conv2.weight.data = conv2weight\n",
    "            model.fc1.weight.data = fc1weight\n",
    "\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "def mainQuantAware(mnist=True):\n",
    " \n",
    "    batch_size = 64\n",
    "    test_batch_size = 64\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 500\n",
    "    save_model = False\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "    if mnist:\n",
    "      train_loader = torch.utils.data.DataLoader(\n",
    "          datasets.MNIST('../data', train=True, download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))\n",
    "                        ])),\n",
    "          batch_size=batch_size, shuffle=True, **kwargs)\n",
    "      \n",
    "      test_loader = torch.utils.data.DataLoader(\n",
    "          datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))\n",
    "                        ])),\n",
    "          batch_size=test_batch_size, shuffle=True, **kwargs)\n",
    "    else:\n",
    "      transform = transforms.Compose(\n",
    "          [transforms.ToTensor(),\n",
    "          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "      trainset = datasets.CIFAR10(root='./dataCifar', train=True,\n",
    "                                              download=True, transform=transform)\n",
    "      train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                                shuffle=True, num_workers=2)\n",
    "\n",
    "      testset = datasets.CIFAR10(root='./dataCifar', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "      test_loader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size,\n",
    "                                              shuffle=False, num_workers=2)\n",
    "          \n",
    "  \n",
    "    model = Net(mnist=mnist).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    epochs = 10\n",
    "    num_bits=4\n",
    "    stats = {}\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        if epoch > 5:\n",
    "          act_quant = True \n",
    "        else:\n",
    "          act_quant = False\n",
    "\n",
    "        stats = trainQuantAware(args, model, device, train_loader, optimizer, epoch, stats, act_quant, num_bits=num_bits)\n",
    "        testQuantAware(args, model, device, test_loader, stats, act_quant, num_bits=num_bits)\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
    "\n",
    "    return model, stats\n",
    "\n",
    "model, old_stats = mainQuantAware()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHGUF12BlAVW"
   },
   "source": [
    "# Test Quantization Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOisGIdHthIt"
   },
   "outputs": [],
   "source": [
    "def testQuantAware(model, test_loader, stats=None, sym=False, num_bits=4):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, conv1weight, conv2weight, fc1weight, _ = quantAwareTrainingForward(model, data, stats, num_bits=num_bits, act_quant=True, sym=False)\n",
    "            \n",
    "            model.conv1.weight.data = conv1weight\n",
    "            model.conv2.weight.data = conv2weight\n",
    "            model.fc1.weight.data = fc1weight\n",
    "\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeBhP7pZlPln"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgWoRSkNzJVM"
   },
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJcX_UQYlSUo"
   },
   "source": [
    "## Test Quant Aware "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "DxmD9WV_l2q2",
    "outputId": "60291599-12fe-4902-eadd-8e23f0fc2bdb"
   },
   "outputs": [],
   "source": [
    "print(old_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sj756_3-lKYy"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "q_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "1eQC5VimyZF-",
    "outputId": "f5fa06bc-82d8-4cb3-cc14-1049bf9826b9"
   },
   "outputs": [],
   "source": [
    "testQuantAware(q_model, test_loader, stats=old_stats, sym=False, num_bits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbJj7GJKmXts"
   },
   "source": [
    "## Voila\n",
    "\n",
    "We're back to test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLMkNQnRpJQ_"
   },
   "source": [
    "# Vis 2 bit Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "id": "ZUdw2hD7zdiM",
    "outputId": "f509bf71-3a6f-4e3e-f4d9-d3f64692b78b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# run through one example and plot weights and activations quantised in real time\n",
    "device = 'cuda'\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        quantForward(q_model, data, old_stats, vis=True, axs=axs, sym=False, num_bits=4)\n",
    "#         output = quantAwareTrainingForward(q_model, data, old_stats, vis=True, axs=axs, sym=False, num_bits=2, act_quant=True)\n",
    "        break\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9QXsrr6Mp5e_",
    "1EWDw3bip8Ie",
    "vFM8UV9CreIX",
    "xXkTAJ9ws1Y6",
    "OgkWg605tE1y",
    "OBt0WDzyujnk",
    "xC96eesMqYo-",
    "mszPTrYOluym",
    "VTHK-wAWV57B"
   ],
   "include_colab_link": true,
   "name": "quantAwareTrain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}